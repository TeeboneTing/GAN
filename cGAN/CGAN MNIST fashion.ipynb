{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN (conditional GAN)\n",
    "\n",
    "**Author:** Teebone Ding\n",
    "\n",
    "**Date:** 2019 Feb\n",
    "\n",
    "Based on Conditional Generative Adversarial Nets (Mirza 2014) [Paper Link](https://arxiv.org/pdf/1411.1784.pdf)\n",
    "\n",
    "Some useful refs while I implementing my cGAN:\n",
    "* keras GAN [Link](https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py)\n",
    "* cGAN in tensorflow version [Link](https://github.com/znxlwm/tensorflow-MNIST-cGAN-cDCGAN)\n",
    "* Paper summary in Chinese version on Zhihu [Link](https://zhuanlan.zhihu.com/p/23648795)\n",
    "\n",
    "Using **MNIST fashion dataset** as playground. For more information about [MNIST fashion](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "My SW/HW setting:\n",
    "* ASUS nVidia GTX 1060 3GB\n",
    "* RAM: 16GB\n",
    "* CPU: Intel Core i5-7400 3.00GHz\n",
    "* Ubuntu 16.04 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST fashion data and data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST fashion data\n",
    "mnist_dataset = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (_, _) = mnist_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_one_hot.shape)\n",
    "print(y_train_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to https://blog.csdn.net/qq_34355232/article/details/79087075\n",
    "# and https://github.com/zalandoresearch/fashion-mnist\n",
    "y_cat = {\n",
    "    0: \"T-shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "#x_train = x_train.astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis=3) # add color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Generator and Discriminator\n",
    "In (Mirza 2014), the paper did not described its architecture really nice. I've modified several parts in both generator and discriminator. This architecture only contain fully connected (FC) layers. In my next iPython notebook, I will try CNN layers to build GAN (cDCGAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Input(shape=(100,))    # Uniform distribution noise input\n",
    "x = Input(shape=(28,28,1)) # image, by real dataset or generator\n",
    "y = Input(shape=(10,))     # label, MNIST one hot encoded with 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          14208       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          66048       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 784)          402192      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 28, 28, 1)    0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 482,448\n",
      "Trainable params: 482,448\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(z,y):\n",
    "    layer = concatenate([z,y])\n",
    "    layer = Dense(128,activation='relu')(layer)\n",
    "    layer = Dense(512,activation='relu')(layer)\n",
    "    layer = Dense(28*28*1,activation='tanh')(layer)\n",
    "    layer = Reshape((28,28,1))(layer)\n",
    "    \n",
    "    model = Model([z,y],layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "G = build_generator(z,y)\n",
    "G.summary() # not compiled, combined with discriminator and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(x,y):\n",
    "    x_flatten = Flatten()(x)\n",
    "    layer = concatenate([x_flatten,y])\n",
    "    layer = Dense(240,activation='relu')(layer)\n",
    "    layer = Dense(1,activation='sigmoid')(layer)\n",
    "    \n",
    "    model = Model([x,y],layer)\n",
    "    return model\n",
    "\n",
    "D = build_discriminator(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While training....\n",
    "# 1. train discriminator first\n",
    "# 2. train a combined (G+D) model, with D is not trainable (only train G)\n",
    "# 3. calculate loss value and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 794)          0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 240)          190800      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            241         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 191,041\n",
      "Trainable params: 191,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Discriminator model\n",
    "#sgd = SGD(lr=0.1, momentum=0.5 ,decay= 1.00004)\n",
    "adam = Adam(0.0002, 0.5)\n",
    "D.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 28, 28, 1)    482448      input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            191041      model[1][0]                      \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 673,489\n",
      "Trainable params: 482,448\n",
      "Non-trainable params: 191,041\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile combined G+D model with D is not trainable\n",
    "img = G([z,y])\n",
    "D.trainable = False\n",
    "valid = D([img,y])\n",
    "C = Model([z,y], valid)\n",
    "C.summary()\n",
    "C.compile(optimizer=adam,loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: x_train, y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate images from Generator network\n",
    "def sample_gen_imgs(epoch):\n",
    "    gen_labels = np.repeat(np.arange(10),10)\n",
    "    gen_labels_cat = to_categorical(gen_labels, num_classes=10)\n",
    "    noises = np.random.normal(0,1,(100,100))\n",
    "    gen_imgs = G.predict([noises,gen_labels_cat])\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    r,c = 10,10\n",
    "    fig, axs = plt.subplots(r, c, figsize=(20, 20))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "            axs[i,j].set_title(\"Cat: %s\" % y_cat[gen_labels[cnt]])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/gen_mnist_fashion_%d.png\"%epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pdb\n",
    "import datetime\n",
    "def train(epochs = 10 ,batch_size = 128): \n",
    "    real_label = np.ones((batch_size,1))\n",
    "    fake_label = np.zeros((batch_size,1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch += 1\n",
    "        for step in range(int(60000/batch_size)):\n",
    "            # Train Discriminator once\n",
    "            # sample real data from training dataset\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            imgs, labels = x_train[idx], y_train_one_hot[idx]\n",
    "            # sample noises from normal dist.\n",
    "            # Somehow I tried uniform dist but cannot trained very well.\n",
    "            noises = np.random.normal(0,1,(batch_size,100))\n",
    "            # generate fake images\n",
    "            gen_imgs = G.predict([noises,labels])\n",
    "            # Train Discriminator\n",
    "            d_real_loss = D.train_on_batch([imgs,labels], real_label) \n",
    "            d_fake_loss = D.train_on_batch([gen_imgs,labels],fake_label)\n",
    "            d_loss = 0.5*np.add(d_real_loss,d_fake_loss)\n",
    "           \n",
    "            # Train Combined model (generator)\n",
    "            gen_labels = to_categorical(np.random.randint(0,10, batch_size),num_classes=10)\n",
    "            # train generator\n",
    "            g_loss = C.train_on_batch([noises,gen_labels], real_label)\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch),end='\\r')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch))\n",
    "            sample_gen_imgs(epoch)\n",
    "            G.save(\"models/G_mnist_fashion_%d.h5\"%epoch)\n",
    "            C.save(\"models/C_mnist_fashion_%d.h5\"%epoch)\n",
    "            D.save(\"models/D_mnist_fashion_%d.h5\"%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-14 12:51:51.402211] D-Loss value: 0.59867 Acc: 0.67000 G-Loss value: 1.16305 in epoch: 10\n",
      "[2019-02-14 12:52:40.182708] D-Loss value: 0.73251 Acc: 0.46500 G-Loss value: 0.92375 in epoch: 20\n",
      "[2019-02-14 12:53:30.238281] D-Loss value: 0.73269 Acc: 0.44000 G-Loss value: 0.80999 in epoch: 30\n",
      "[2019-02-14 12:54:21.222648] D-Loss value: 0.70672 Acc: 0.41500 G-Loss value: 0.73908 in epoch: 40\n",
      "[2019-02-14 12:55:09.798607] D-Loss value: 0.71005 Acc: 0.39000 G-Loss value: 0.75095 in epoch: 50\n",
      "[2019-02-14 12:55:57.362970] D-Loss value: 0.70212 Acc: 0.47000 G-Loss value: 0.72447 in epoch: 60\n",
      "[2019-02-14 12:56:44.830046] D-Loss value: 0.70431 Acc: 0.37000 G-Loss value: 0.70557 in epoch: 70\n",
      "[2019-02-14 12:57:34.140066] D-Loss value: 0.69663 Acc: 0.45000 G-Loss value: 0.71511 in epoch: 80\n",
      "[2019-02-14 12:58:27.841596] D-Loss value: 0.70060 Acc: 0.37500 G-Loss value: 0.70245 in epoch: 90\n",
      "[2019-02-14 12:59:21.399008] D-Loss value: 0.69189 Acc: 0.50000 G-Loss value: 0.70246 in epoch: 100\n",
      "[2019-02-14 13:00:11.319465] D-Loss value: 0.69808 Acc: 0.37000 G-Loss value: 0.70811 in epoch: 110\n",
      "[2019-02-14 13:00:59.231851] D-Loss value: 0.69808 Acc: 0.45500 G-Loss value: 0.70599 in epoch: 120\n",
      "[2019-02-14 13:01:46.908894] D-Loss value: 0.69180 Acc: 0.51000 G-Loss value: 0.72564 in epoch: 130\n",
      "[2019-02-14 13:02:35.110108] D-Loss value: 0.69852 Acc: 0.45000 G-Loss value: 0.69856 in epoch: 140\n",
      "[2019-02-14 13:03:26.264032] D-Loss value: 0.67744 Acc: 0.51500 G-Loss value: 0.70432 in epoch: 150\n",
      "[2019-02-14 13:04:14.873543] D-Loss value: 0.69582 Acc: 0.41500 G-Loss value: 0.69052 in epoch: 160\n",
      "[2019-02-14 13:05:08.230224] D-Loss value: 0.68419 Acc: 0.53500 G-Loss value: 0.72038 in epoch: 170\n",
      "[2019-02-14 13:05:59.095909] D-Loss value: 0.69217 Acc: 0.51000 G-Loss value: 0.71814 in epoch: 180\n",
      "[2019-02-14 13:06:50.162739] D-Loss value: 0.70286 Acc: 0.50500 G-Loss value: 0.71196 in epoch: 190\n",
      "[2019-02-14 13:07:39.958039] D-Loss value: 0.69273 Acc: 0.49000 G-Loss value: 0.70259 in epoch: 200\n"
     ]
    }
   ],
   "source": [
    "train(epochs=200, batch_size = 100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Generated images after 200 epochs\n",
    "![alt text](images/gen_mnist_fashion_200.png \"Gen image 200 epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
