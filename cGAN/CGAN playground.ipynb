{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN (conditional GAN)\n",
    "\n",
    "**Author:** Teebone Ding\n",
    "\n",
    "**Date:** 2019 Feb\n",
    "\n",
    "Based on Conditional Generative Adversarial Nets (Mirza 2014) [Paper Link](https://arxiv.org/pdf/1411.1784.pdf)\n",
    "\n",
    "Some useful refs while I implementing my cGAN:\n",
    "* keras GAN [Link](https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py)\n",
    "* cGAN in tensorflow version [Link](https://github.com/znxlwm/tensorflow-MNIST-cGAN-cDCGAN)\n",
    "* Paper summary in Chinese version on Zhihu [Link](https://zhuanlan.zhihu.com/p/23648795)\n",
    "\n",
    "Using MNIST dataset as playground\n",
    "\n",
    "My SW/HW setting:\n",
    "* ASUS nVidia GTX 1060 3GB\n",
    "* RAM: 16GB\n",
    "* CPU: Intel Core i5-7400 3.00GHz\n",
    "* Ubuntu 16.04 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data and data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "mnist_dataset = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_ont_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_one_hot.shape)\n",
    "print(y_train_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "#x_train = x_train.astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis=3) # add color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Generator and Discriminator\n",
    "In (Mirza 2014), the paper did not described its architecture really nice. I've modified several parts in both generator and discriminator. This architecture only contain fully connected (FC) layers. In my next iPython notebook, I will try CNN layers to build GAN (cDCGAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Input(shape=(100,))    # Uniform distribution noise input\n",
    "x = Input(shape=(28,28,1)) # image, by real dataset or generator\n",
    "y = Input(shape=(10,))     # label, MNIST one hot encoded with 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          14208       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          66048       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 784)          402192      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 28, 28, 1)    0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 482,448\n",
      "Trainable params: 482,448\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(z,y):\n",
    "    #z_1 = Dense(200,activation='relu')(z)\n",
    "    #y_1 = Dense(1000,activation='relu')(y)\n",
    "    layer = concatenate([z,y])\n",
    "    layer = Dense(128,activation='relu')(layer)\n",
    "    layer = Dense(512,activation='relu')(layer)\n",
    "    layer = Dense(28*28*1,activation='tanh')(layer)\n",
    "    layer = Reshape((28,28,1))(layer)\n",
    "    \n",
    "    model = Model([z,y],layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "G = build_generator(z,y)\n",
    "G.summary() # not compiled, combined with discriminator and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(x,y):\n",
    "    x_flatten = Flatten()(x)\n",
    "    #x_1 = Dense(240,activation='relu')(x_flatten)\n",
    "    #y_1 = Dense(50,activation='relu')(y)\n",
    "    layer = concatenate([x_flatten,y])\n",
    "    layer = Dense(240,activation='relu')(layer)\n",
    "    layer = Dense(1,activation='sigmoid')(layer)\n",
    "    \n",
    "    model = Model([x,y],layer)\n",
    "    return model\n",
    "\n",
    "D = build_discriminator(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While training....\n",
    "# 1. train discriminator first\n",
    "# 2. train a combined (G+D) model, with D is not trainable (only train G)\n",
    "# 3. calculate loss value and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 794)          0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 240)          190800      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            241         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 191,041\n",
      "Trainable params: 191,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Discriminator model\n",
    "sgd = SGD(lr=0.1, momentum=0.5 ,decay= 1.00004)\n",
    "adam = Adam(0.0002, 0.5)\n",
    "D.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 28, 28, 1)    482448      input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            191041      model[1][0]                      \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 673,489\n",
      "Trainable params: 482,448\n",
      "Non-trainable params: 191,041\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile combined G+D model with D is not trainable\n",
    "img = G([z,y])\n",
    "D.trainable = False\n",
    "valid = D([img,y])\n",
    "C = Model([z,y], valid)\n",
    "C.summary()\n",
    "C.compile(optimizer=adam,loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: x_train, y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate images from Generator network\n",
    "def sample_gen_imgs(epoch):\n",
    "    gen_labels = np.repeat(np.arange(10),10)\n",
    "    gen_labels_cat = to_categorical(gen_labels, num_classes=10)\n",
    "    noises = np.random.normal(0,1,(100,100))\n",
    "    gen_imgs = G.predict([noises,gen_labels_cat])\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    r,c = 10,10\n",
    "    fig, axs = plt.subplots(r, c, figsize=(20, 20))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "            axs[i,j].set_title(\"Digit: %d\" % gen_labels[cnt])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/gen_%d.png\"%epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pdb\n",
    "import datetime\n",
    "def train(epochs = 10 ,batch_size = 128): \n",
    "    real_label = np.ones((batch_size,1))\n",
    "    fake_label = np.zeros((batch_size,1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch += 1\n",
    "        for step in range(int(60000/batch_size)):\n",
    "            # Train Discriminator once\n",
    "            # sample real data from training dataset\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            imgs, labels = x_train[idx], y_train_one_hot[idx]\n",
    "            # sample noises from normal dist.\n",
    "            # Somehow I tried uniform dist but cannot trained very well.\n",
    "            noises = np.random.normal(0,1,(batch_size,100))\n",
    "            # generate fake images\n",
    "            gen_imgs = G.predict([noises,labels])\n",
    "            # Train Discriminator\n",
    "            d_real_loss = D.train_on_batch([imgs,labels], real_label) \n",
    "            d_fake_loss = D.train_on_batch([gen_imgs,labels],fake_label)\n",
    "            d_loss = 0.5*np.add(d_real_loss,d_fake_loss)\n",
    "           \n",
    "            # Train Combined model (generator)\n",
    "            gen_labels = to_categorical(np.random.randint(0,10, batch_size),num_classes=10)\n",
    "            # train generator\n",
    "            g_loss = C.train_on_batch([noises,gen_labels], real_label)\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch),end='\\r')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch))\n",
    "            sample_gen_imgs(epoch)\n",
    "            G.save(\"models/G_%d.h5\"%epoch)\n",
    "            C.save(\"models/C_%d.h5\"%epoch)\n",
    "            D.save(\"models/D_%d.h5\"%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-14 11:45:42.786548] D-Loss value: 0.26010 Acc: 0.94500 G-Loss value: 2.56396 in epoch: 10\n",
      "[2019-02-14 11:46:32.619304] D-Loss value: 0.60281 Acc: 0.64500 G-Loss value: 1.37500 in epoch: 20\n",
      "[2019-02-14 11:47:28.262280] D-Loss value: 0.70990 Acc: 0.56500 G-Loss value: 0.96813 in epoch: 30\n",
      "[2019-02-14 11:48:21.934251] D-Loss value: 0.72252 Acc: 0.45500 G-Loss value: 0.80350 in epoch: 40\n",
      "[2019-02-14 11:49:14.355797] D-Loss value: 0.71558 Acc: 0.50000 G-Loss value: 0.84901 in epoch: 50\n",
      "[2019-02-14 11:50:04.852742] D-Loss value: 0.74334 Acc: 0.43000 G-Loss value: 0.81839 in epoch: 60\n",
      "[2019-02-14 11:50:55.733737] D-Loss value: 0.68448 Acc: 0.58000 G-Loss value: 0.85500 in epoch: 70\n",
      "[2019-02-14 11:51:47.507269] D-Loss value: 0.71111 Acc: 0.48500 G-Loss value: 0.80015 in epoch: 80\n",
      "[2019-02-14 11:52:37.059630] D-Loss value: 0.69949 Acc: 0.51500 G-Loss value: 0.77844 in epoch: 90\n",
      "[2019-02-14 11:53:25.365653] D-Loss value: 0.66602 Acc: 0.56000 G-Loss value: 0.83334 in epoch: 100\n",
      "[2019-02-14 11:54:20.910125] D-Loss value: 0.69519 Acc: 0.50500 G-Loss value: 0.79810 in epoch: 110\n",
      "[2019-02-14 11:55:12.037684] D-Loss value: 0.70072 Acc: 0.48000 G-Loss value: 0.80888 in epoch: 120\n",
      "[2019-02-14 11:56:02.344585] D-Loss value: 0.66312 Acc: 0.59500 G-Loss value: 0.75679 in epoch: 130\n",
      "[2019-02-14 11:56:50.596714] D-Loss value: 0.69265 Acc: 0.50000 G-Loss value: 0.83776 in epoch: 140\n",
      "[2019-02-14 11:57:42.074179] D-Loss value: 0.66649 Acc: 0.58000 G-Loss value: 0.80931 in epoch: 150\n",
      "[2019-02-14 11:58:30.475039] D-Loss value: 0.68915 Acc: 0.54500 G-Loss value: 0.77858 in epoch: 160\n",
      "[2019-02-14 11:59:19.789848] D-Loss value: 0.68992 Acc: 0.55500 G-Loss value: 0.76728 in epoch: 170\n",
      "[2019-02-14 12:00:08.004080] D-Loss value: 0.67463 Acc: 0.57000 G-Loss value: 0.78976 in epoch: 180\n",
      "[2019-02-14 12:00:57.602552] D-Loss value: 0.69113 Acc: 0.46000 G-Loss value: 0.76591 in epoch: 190\n",
      "[2019-02-14 12:01:46.143703] D-Loss value: 0.69525 Acc: 0.51500 G-Loss value: 0.75552 in epoch: 200\n"
     ]
    }
   ],
   "source": [
    "train(epochs=200, batch_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated images after 200 epochs\n",
    "![alt text](images/gen_200.png \"Gen image 200 epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
