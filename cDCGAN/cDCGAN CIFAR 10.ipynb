{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cDCGAN (conditional Deep Convolutional GAN)\n",
    "\n",
    "**Author:** Teebone Ding\n",
    "\n",
    "**Date:** 2019 Feb\n",
    "\n",
    "Based on DCGAN (Radford, Metz, 2016) [Paper Link](https://arxiv.org/pdf/1511.06434.pdf)\n",
    "\n",
    "Some useful refs while I implementing my cDCGAN:\n",
    "* keras GAN [Link](https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py)\n",
    "* cDCGAN in tensorflow version [Link](https://github.com/znxlwm/tensorflow-MNIST-cGAN-cDCGAN)\n",
    "* cDCGAN using keras [Link](https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610)\n",
    "\n",
    "Using **CIFAR 10 dataset** as playground.\n",
    "\n",
    "My SW/HW setting:\n",
    "* ASUS nVidia GTX 1060 3GB\n",
    "* RAM: 16GB\n",
    "* CPU: Intel Core i5-7400 3.00GHz\n",
    "* Ubuntu 16.04 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR 10 data and data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10 data\n",
    "cifar10_dataset = keras.datasets.cifar10\n",
    "(x_train, y_train), (_, _) = cifar10_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/EN10/CIFAR\n",
    "y_cat = {\n",
    "    0 : \"airplane\",\n",
    "    1 : \"automobile\",\n",
    "    2 : \"bird\",\n",
    "    3 : \"cat\",\n",
    "    4 : \"deer\",\n",
    "    5 : \"dog\",\n",
    "    6 : \"frog\",\n",
    "    7 : \"horse\",\n",
    "    8 : \"ship\",\n",
    "    9 : \"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_one_hot.shape)\n",
    "print(y_train_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [7],\n",
       "       [8],\n",
       "       [3]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "#x_train = x_train.astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Generator and Discriminator\n",
    "Try CNN layers to build GAN (cDCGAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, ReLU, UpSampling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Input(shape=(100,))    # Normal distribution noise input\n",
    "x = Input(shape=(32,32,3)) # image, by real dataset or generator\n",
    "y = Input(shape=(10,))     # label, MNIST one hot encoded with 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         454656      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4096)         16384       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 4096)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4, 4, 256)    0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 128)    819328      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 128)    512         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   204864      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 3)    4803        leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,500,803\n",
      "Trainable params: 1,492,227\n",
      "Non-trainable params: 8,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(z,y):\n",
    "    layer = Concatenate()([z,y])\n",
    "    \n",
    "    layer = Dense((4*4*256))(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Reshape((4,4,256))(layer)\n",
    "    \n",
    "    layer = Conv2DTranspose(128,5,strides=2,padding='same')(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "\n",
    "    layer = Conv2DTranspose(64,5,strides=2, activation='relu',padding='same')(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "\n",
    "    layer = Conv2DTranspose(3,5,strides=2, activation='tanh',padding='same')(layer)\n",
    "    \n",
    "    model = Model([z,y],layer)\n",
    "\n",
    "    return model,layer\n",
    "\n",
    "G,G_out = build_generator(z,y)\n",
    "G.summary() # not compiled, combined with discriminator and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(x,y):\n",
    "    layer = Conv2D(32,3,strides=2,padding=\"same\")(x)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    \n",
    "    layer = Conv2D(64,3,strides=2,padding=\"same\")(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    \n",
    "    layer = Conv2D(128,3,strides=2,padding=\"same\")(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Concatenate()([layer, y])\n",
    "    layer = Dense(256,activation='relu')(layer)\n",
    "    \n",
    "    layer = Dense(1,activation='sigmoid')(layer)\n",
    "    \n",
    "    model = Model([x,y],layer)\n",
    "    return model, layer\n",
    "\n",
    "D, D_out = build_discriminator(x,y)\n",
    "#D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While training....\n",
    "# 1. train discriminator first\n",
    "# 2. train a combined (G+D) model, with D is not trainable (only train G)\n",
    "# 3. calculate loss value and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 32)   896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, 32)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 64)     18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 64)     0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 128)    512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 128)    0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2058)         0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          527104      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 621,377\n",
      "Trainable params: 620,993\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Discriminator model\n",
    "#sgd = SGD(lr=0.1, momentum=0.5 ,decay= 1.00004)\n",
    "adam = Adam(0.0002, 0.5)\n",
    "D.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 32, 32, 3)    1500803     input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            621377      model[1][0]                      \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,122,180\n",
      "Trainable params: 1,492,227\n",
      "Non-trainable params: 629,953\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile combined G+D model with D is not trainable\n",
    "img = G([z,y])\n",
    "D.trainable = False\n",
    "valid = D([img,y])\n",
    "C = Model([z,y], valid)\n",
    "C.summary()\n",
    "C.compile(optimizer=adam,loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: x_train, y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate images from Generator network\n",
    "def sample_gen_imgs(epoch):\n",
    "    gen_labels = np.repeat(np.arange(10),10)\n",
    "    gen_labels_cat = to_categorical(gen_labels, num_classes=10)\n",
    "    noises = np.random.normal(0,1,(100,100))\n",
    "    gen_imgs = G.predict([noises,gen_labels_cat])\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    r,c = 10,10\n",
    "    fig, axs = plt.subplots(r, c, figsize=(20, 20))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n",
    "            axs[i,j].set_title(\"Cat: %s\" % y_cat[gen_labels[cnt]])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/gen_cifar10_%d.png\"%epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import datetime\n",
    "def train(epochs = 10 ,batch_size = 128): \n",
    "    real_label = np.ones((batch_size,1))\n",
    "    fake_label = np.zeros((batch_size,1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch += 1\n",
    "        for step in range(int(x_train.shape[0]/batch_size)):\n",
    "            # Train Discriminator once\n",
    "            # sample real data from training dataset\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            imgs, labels = x_train[idx], y_train_one_hot[idx]\n",
    "            # sample noises from normal dist.\n",
    "            # Somehow I tried uniform dist but cannot trained very well.\n",
    "            noises = np.random.normal(0,1,(batch_size,100))\n",
    "            # generate fake images\n",
    "            gen_imgs = G.predict([noises,labels])\n",
    "            #pdb.set_trace()\n",
    "            # Train Discriminator\n",
    "            d_real_loss = D.train_on_batch([imgs,labels], real_label) \n",
    "            d_fake_loss = D.train_on_batch([gen_imgs,labels],fake_label)\n",
    "            d_loss = 0.5*np.add(d_real_loss,d_fake_loss)\n",
    "           \n",
    "            # Train Combined model (generator)\n",
    "            gen_labels = to_categorical(np.random.randint(0,10, batch_size),num_classes=10)\n",
    "            # train generator\n",
    "            g_loss = C.train_on_batch([noises,gen_labels], real_label)\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch),end='\\r')\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch))\n",
    "            sample_gen_imgs(epoch)\n",
    "            G.save(\"models/G_cifar10_%d.h5\"%epoch)\n",
    "            C.save(\"models/C_cifar10_%d.h5\"%epoch)\n",
    "            D.save(\"models/D_cifar10_%d.h5\"%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-17 01:34:31.233285] D-Loss value: 0.65242 Acc: 0.55859 G-Loss value: 0.81228 in epoch: 5\n",
      "[2019-02-17 01:36:47.721813] D-Loss value: 0.64420 Acc: 0.59375 G-Loss value: 0.86993 in epoch: 10\n",
      "[2019-02-17 01:39:02.077943] D-Loss value: 0.61034 Acc: 0.65234 G-Loss value: 0.82328 in epoch: 15\n",
      "[2019-02-17 01:41:17.647435] D-Loss value: 0.63431 Acc: 0.62500 G-Loss value: 0.99098 in epoch: 20\n",
      "[2019-02-17 01:43:32.604386] D-Loss value: 0.61807 Acc: 0.67969 G-Loss value: 0.97781 in epoch: 25\n",
      "[2019-02-17 01:45:47.201714] D-Loss value: 0.59697 Acc: 0.66406 G-Loss value: 1.03059 in epoch: 30\n",
      "[2019-02-17 01:48:00.784945] D-Loss value: 0.56278 Acc: 0.69531 G-Loss value: 1.31992 in epoch: 35\n",
      "[2019-02-17 01:50:13.981386] D-Loss value: 0.57437 Acc: 0.67969 G-Loss value: 1.16380 in epoch: 40\n",
      "[2019-02-17 01:52:26.423468] D-Loss value: 0.57058 Acc: 0.69531 G-Loss value: 1.29966 in epoch: 45\n",
      "[2019-02-17 01:54:39.153861] D-Loss value: 0.51956 Acc: 0.75000 G-Loss value: 1.34080 in epoch: 50\n",
      "[2019-02-17 01:56:51.649638] D-Loss value: 0.53731 Acc: 0.70312 G-Loss value: 1.27472 in epoch: 55\n",
      "[2019-02-17 01:59:03.245614] D-Loss value: 0.50402 Acc: 0.75391 G-Loss value: 1.37123 in epoch: 60\n",
      "[2019-02-17 02:01:14.720396] D-Loss value: 0.48397 Acc: 0.78516 G-Loss value: 1.36307 in epoch: 65\n",
      "[2019-02-17 02:03:26.953201] D-Loss value: 0.54619 Acc: 0.71875 G-Loss value: 1.32137 in epoch: 70\n",
      "[2019-02-17 02:05:39.045491] D-Loss value: 0.46431 Acc: 0.77344 G-Loss value: 1.59372 in epoch: 75\n",
      "[2019-02-17 02:07:50.852680] D-Loss value: 0.53699 Acc: 0.73438 G-Loss value: 1.57038 in epoch: 80\n",
      "[2019-02-17 02:10:02.075908] D-Loss value: 0.52036 Acc: 0.75391 G-Loss value: 1.56116 in epoch: 85\n",
      "[2019-02-17 02:12:14.800485] D-Loss value: 0.54248 Acc: 0.70703 G-Loss value: 1.62128 in epoch: 90\n",
      "[2019-02-17 02:14:25.467752] D-Loss value: 0.45367 Acc: 0.77734 G-Loss value: 1.60461 in epoch: 95\n",
      "[2019-02-17 02:16:37.217887] D-Loss value: 0.47628 Acc: 0.78125 G-Loss value: 1.51948 in epoch: 100\n",
      "[2019-02-17 02:18:46.282280] D-Loss value: 0.56752 Acc: 0.73828 G-Loss value: 1.52883 in epoch: 105\n",
      "[2019-02-17 02:20:54.793734] D-Loss value: 0.53091 Acc: 0.71484 G-Loss value: 1.63672 in epoch: 110\n",
      "[2019-02-17 02:23:05.877733] D-Loss value: 0.50013 Acc: 0.76172 G-Loss value: 1.51248 in epoch: 115\n",
      "[2019-02-17 02:25:15.270217] D-Loss value: 0.50738 Acc: 0.73438 G-Loss value: 1.53425 in epoch: 120\n",
      "[2019-02-17 02:27:24.166654] D-Loss value: 0.50544 Acc: 0.74609 G-Loss value: 1.75068 in epoch: 125\n",
      "[2019-02-17 02:29:34.143896] D-Loss value: 0.46536 Acc: 0.78516 G-Loss value: 1.61044 in epoch: 130\n",
      "[2019-02-17 02:31:42.799229] D-Loss value: 0.44929 Acc: 0.80859 G-Loss value: 1.61244 in epoch: 135\n",
      "[2019-02-17 02:33:52.256083] D-Loss value: 0.46690 Acc: 0.79297 G-Loss value: 1.69174 in epoch: 140\n",
      "[2019-02-17 02:36:03.355434] D-Loss value: 0.49910 Acc: 0.72656 G-Loss value: 1.67431 in epoch: 145\n",
      "[2019-02-17 02:38:13.534698] D-Loss value: 0.43660 Acc: 0.82031 G-Loss value: 1.74728 in epoch: 150\n",
      "[2019-02-17 02:40:22.116973] D-Loss value: 0.48310 Acc: 0.75781 G-Loss value: 1.53244 in epoch: 155\n",
      "[2019-02-17 02:42:33.082646] D-Loss value: 0.48832 Acc: 0.76562 G-Loss value: 1.64902 in epoch: 160\n",
      "[2019-02-17 02:44:42.622519] D-Loss value: 0.46469 Acc: 0.79297 G-Loss value: 1.53271 in epoch: 165\n",
      "[2019-02-17 02:46:50.657221] D-Loss value: 0.37085 Acc: 0.84375 G-Loss value: 1.61996 in epoch: 170\n",
      "[2019-02-17 02:48:57.389053] D-Loss value: 0.48458 Acc: 0.75391 G-Loss value: 1.69631 in epoch: 175\n",
      "[2019-02-17 02:51:07.126140] D-Loss value: 0.50016 Acc: 0.74609 G-Loss value: 1.59134 in epoch: 180\n",
      "[2019-02-17 02:53:16.234305] D-Loss value: 0.53159 Acc: 0.76562 G-Loss value: 1.64974 in epoch: 185\n",
      "[2019-02-17 02:55:28.663513] D-Loss value: 0.47467 Acc: 0.75391 G-Loss value: 1.65693 in epoch: 190\n",
      "[2019-02-17 02:57:36.396131] D-Loss value: 0.48581 Acc: 0.76953 G-Loss value: 1.72309 in epoch: 195\n",
      "[2019-02-17 02:59:45.599120] D-Loss value: 0.45880 Acc: 0.76953 G-Loss value: 1.74635 in epoch: 200\n"
     ]
    }
   ],
   "source": [
    "train(epochs=200, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated images after 200 epochs\n",
    "![alt text](images/gen_cifar10_200.png \"Gen image 200 epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
