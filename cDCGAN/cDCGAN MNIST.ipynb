{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cDCGAN (conditional Deep Convolutional GAN)\n",
    "\n",
    "**Author:** Teebone Ding\n",
    "\n",
    "**Date:** 2019 Feb\n",
    "\n",
    "Based on DCGAN (Radford, Metz, 2016) [Paper Link](https://arxiv.org/pdf/1511.06434.pdf)\n",
    "\n",
    "Some useful refs while I implementing my cDCGAN:\n",
    "* keras GAN [Link](https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py)\n",
    "* cDCGAN in tensorflow version [Link](https://github.com/znxlwm/tensorflow-MNIST-cGAN-cDCGAN)\n",
    "* cDCGAN using keras [Link](https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610)\n",
    "\n",
    "Using **MNIST dataset** as playground.\n",
    "My SW/HW setting:\n",
    "* ASUS nVidia GTX 1060 3GB\n",
    "* RAM: 16GB\n",
    "* CPU: Intel Core i5-7400 3.00GHz\n",
    "* Ubuntu 16.04 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data and data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST fashion data\n",
    "#mnist_dataset = keras.datasets.fashion_mnist\n",
    "mnist_dataset = keras.datasets.mnist\n",
    "(x_train, y_train), (_, _) = mnist_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_one_hot.shape)\n",
    "print(y_train_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "#x_train = x_train.astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis=3) # add color channel\n",
    "#x_train = x_train.reshape((60000,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Generator and Discriminator\n",
    "Try CNN layers to build GAN (cDCGAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, ReLU, UpSampling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Input(shape=(100,))    # Uniform distribution noise input\n",
    "x = Input(shape=(28,28,1)) # image, by real dataset or generator\n",
    "#x = Input(shape=(784,))\n",
    "y = Input(shape=(10,))     # label, MNIST one hot encoded with 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         454656      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4096)         16384       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 4096)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4, 4, 256)    0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 128)    819328      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 128)    512         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 24, 24, 64)   204864      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 24, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 24, 24, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 1)    1601        leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,497,601\n",
      "Trainable params: 1,489,025\n",
      "Non-trainable params: 8,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(z,y):\n",
    "    layer = Concatenate()([z,y])\n",
    "    \n",
    "    layer = Dense((4*4*256))(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Reshape((4,4,256))(layer)\n",
    "    \n",
    "    layer = Conv2DTranspose(128,5,strides=2,padding='same')(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "\n",
    "    layer = Conv2DTranspose(64,5,strides=3, activation='relu',padding='same')(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "\n",
    "    layer = Conv2DTranspose(1,5,strides=1, activation='tanh',padding='valid')(layer)\n",
    "    #layer = Flatten()(layer)\n",
    "    \n",
    "    model = Model([z,y],layer)\n",
    "\n",
    "    return model,layer\n",
    "\n",
    "G,G_out = build_generator(z,y)\n",
    "G.summary() # not compiled, combined with discriminator and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 32)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 128)    512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 128)    0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2058)         0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          527104      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 620,801\n",
      "Trainable params: 620,417\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_discriminator(x,y):\n",
    "    layer = Conv2D(32,3,strides=2,padding=\"same\")(x)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    \n",
    "    layer = Conv2D(64,3,strides=2,padding=\"same\")(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    \n",
    "    layer = Conv2D(128,3,strides=2,padding=\"same\")(layer)\n",
    "    layer = BatchNormalization(momentum=0.8)(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Concatenate()([layer, y])\n",
    "    layer = Dense(256,activation='relu')(layer)\n",
    "    \n",
    "    layer = Dense(1,activation='sigmoid')(layer)\n",
    "    \n",
    "    model = Model([x,y],layer)\n",
    "    return model, layer\n",
    "\n",
    "D, D_out = build_discriminator(x,y)\n",
    "#D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While training....\n",
    "# 1. train discriminator first\n",
    "# 2. train a combined (G+D) model, with D is not trainable (only train G)\n",
    "# 3. calculate loss value and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 32)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 128)    512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 128)    0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2058)         0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          527104      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 620,801\n",
      "Trainable params: 620,417\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Discriminator model\n",
    "#sgd = SGD(lr=0.1, momentum=0.5 ,decay= 1.00004)\n",
    "adam = Adam(0.0002, 0.5)\n",
    "D.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 28, 28, 1)    1497601     input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            620801      model[2][0]                      \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,118,402\n",
      "Trainable params: 1,489,025\n",
      "Non-trainable params: 629,377\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile combined G+D model with D is not trainable\n",
    "img = G([z,y])\n",
    "D.trainable = False\n",
    "valid = D([img,y])\n",
    "C = Model([z,y], valid)\n",
    "C.summary()\n",
    "C.compile(optimizer=adam,loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: x_train, y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate images from Generator network\n",
    "def sample_gen_imgs(epoch):\n",
    "    gen_labels = np.repeat(np.arange(10),10)\n",
    "    gen_labels_cat = to_categorical(gen_labels, num_classes=10)\n",
    "    noises = np.random.normal(0,1,(100,100))\n",
    "    gen_imgs = G.predict([noises,gen_labels_cat])\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    r,c = 10,10\n",
    "    fig, axs = plt.subplots(r, c, figsize=(20, 20))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "            #axs[i,j].set_title(\"Cat: %s\" % y_cat[gen_labels[cnt]])\n",
    "            axs[i,j].set_title(\"Digits: %s\" % gen_labels[cnt])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/gen_mnist_%d.png\"%epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import datetime\n",
    "def train(epochs = 10 ,batch_size = 128): \n",
    "    real_label = np.ones((batch_size,1))\n",
    "    fake_label = np.zeros((batch_size,1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch += 1\n",
    "        for step in range(int(60000/batch_size)):\n",
    "            # Train Discriminator once\n",
    "            # sample real data from training dataset\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            imgs, labels = x_train[idx], y_train_one_hot[idx]\n",
    "            # sample noises from normal dist.\n",
    "            # Somehow I tried uniform dist but cannot trained very well.\n",
    "            noises = np.random.normal(0,1,(batch_size,100))\n",
    "            # generate fake images\n",
    "            gen_imgs = G.predict([noises,labels])\n",
    "            #pdb.set_trace()\n",
    "            # Train Discriminator\n",
    "            d_real_loss = D.train_on_batch([imgs,labels], real_label) \n",
    "            d_fake_loss = D.train_on_batch([gen_imgs,labels],fake_label)\n",
    "            d_loss = 0.5*np.add(d_real_loss,d_fake_loss)\n",
    "           \n",
    "            # Train Combined model (generator)\n",
    "            gen_labels = to_categorical(np.random.randint(0,10, batch_size),num_classes=10)\n",
    "            # train generator\n",
    "            g_loss = C.train_on_batch([noises,gen_labels], real_label)\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch),end='\\r')\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(\"[%s] D-Loss value: %.5f Acc: %.5f G-Loss value: %.5f in epoch: %d\"%(datetime.datetime.now(),d_loss[0],d_loss[1], g_loss, epoch))\n",
    "            sample_gen_imgs(epoch)\n",
    "            G.save(\"models/G_mnist_%d.h5\"%epoch)\n",
    "            C.save(\"models/C_mnist_%d.h5\"%epoch)\n",
    "            D.save(\"models/D_mnist_%d.h5\"%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-02-17 00:27:45.613657] D-Loss value: 0.65597 Acc: 0.58594 G-Loss value: 0.81672 in epoch: 5\n",
      "[2019-02-17 00:31:04.388116] D-Loss value: 0.65510 Acc: 0.57031 G-Loss value: 0.92401 in epoch: 10\n",
      "[2019-02-17 00:34:20.722020] D-Loss value: 0.62054 Acc: 0.65625 G-Loss value: 0.88760 in epoch: 15\n",
      "[2019-02-17 00:37:38.796056] D-Loss value: 0.63429 Acc: 0.64062 G-Loss value: 0.88756 in epoch: 20\n"
     ]
    }
   ],
   "source": [
    "train(epochs=20, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated images after 20 epochs\n",
    "![alt text](images/gen_mnist_fashion_20.png \"Gen image 200 epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
